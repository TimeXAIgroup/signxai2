

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Explanation Methods List &mdash; SignXAI 1.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=ec77c5b5" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=8d563738"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Utilities" href="utils.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #2980B9" >

          
          
          <a href="../index.html" class="icon icon-home">
            SignXAI
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../guide/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/basic_usage.html">Basic Usage</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../guide/framework_interop.html">Framework Interoperability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/advanced_usage.html">Advanced Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/visualization.html">Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/tensorflow.html">TensorFlow Implementation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/pytorch.html">PyTorch Implementation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/image_classification.html">Image Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/time_series.html">ECG Time Series</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="tensorflow.html">TensorFlow Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="pytorch.html">PyTorch Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="common.html">Common Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">Utilities</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Explanation Methods List</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#library-attribution">Library Attribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="#method-overview">Method Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#gradient-based-methods">Gradient-Based Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#vanilla-gradient">Vanilla Gradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="#gradient-x-input">Gradient x Input</a></li>
<li class="toctree-l3"><a class="reference internal" href="#gradient-x-sign">Gradient x SIGN</a></li>
<li class="toctree-l3"><a class="reference internal" href="#integrated-gradients">Integrated Gradients</a></li>
<li class="toctree-l3"><a class="reference internal" href="#smoothgrad">SmoothGrad</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#guided-backpropagation">Guided Backpropagation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#grad-cam">Grad-CAM</a></li>
<li class="toctree-l2"><a class="reference internal" href="#layer-wise-relevance-propagation-lrp">Layer-wise Relevance Propagation (LRP)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#lrp-base-methods">LRP Base Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lrp-with-epsilon">LRP with Epsilon</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lrp-with-alpha-beta">LRP with Alpha-Beta</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lrp-composite-rules">LRP Composite Rules</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#framework-specific-parameters">Framework-Specific Parameters</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#tensorflow-specific-parameters">TensorFlow-Specific Parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pytorch-specific-parameters">PyTorch-Specific Parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="#common-parameters">Common Parameters</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #2980B9" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">SignXAI</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Explanation Methods List</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/signxai/signxai/blob/main/docs/api/methods_list.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="explanation-methods-list">
<h1>Explanation Methods List<a class="headerlink" href="#explanation-methods-list" title="Link to this heading"></a></h1>
<p>SignXAI provides a comprehensive list of explanation methods for both TensorFlow and PyTorch models. This page details all available methods, their parameters, and framework compatibility.</p>
<nav class="contents local" id="contents">
<p class="topic-title">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#library-attribution" id="id2">Library Attribution</a></p></li>
<li><p><a class="reference internal" href="#method-overview" id="id3">Method Overview</a></p></li>
<li><p><a class="reference internal" href="#gradient-based-methods" id="id4">Gradient-Based Methods</a></p>
<ul>
<li><p><a class="reference internal" href="#vanilla-gradient" id="id5">Vanilla Gradient</a></p></li>
<li><p><a class="reference internal" href="#gradient-x-input" id="id6">Gradient x Input</a></p></li>
<li><p><a class="reference internal" href="#gradient-x-sign" id="id7">Gradient x SIGN</a></p></li>
<li><p><a class="reference internal" href="#integrated-gradients" id="id8">Integrated Gradients</a></p></li>
<li><p><a class="reference internal" href="#smoothgrad" id="id9">SmoothGrad</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#guided-backpropagation" id="id10">Guided Backpropagation</a></p></li>
<li><p><a class="reference internal" href="#grad-cam" id="id11">Grad-CAM</a></p></li>
<li><p><a class="reference internal" href="#layer-wise-relevance-propagation-lrp" id="id12">Layer-wise Relevance Propagation (LRP)</a></p>
<ul>
<li><p><a class="reference internal" href="#lrp-base-methods" id="id13">LRP Base Methods</a></p></li>
<li><p><a class="reference internal" href="#lrp-with-epsilon" id="id14">LRP with Epsilon</a></p></li>
<li><p><a class="reference internal" href="#lrp-with-alpha-beta" id="id15">LRP with Alpha-Beta</a></p></li>
<li><p><a class="reference internal" href="#lrp-composite-rules" id="id16">LRP Composite Rules</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#framework-specific-parameters" id="id17">Framework-Specific Parameters</a></p>
<ul>
<li><p><a class="reference internal" href="#tensorflow-specific-parameters" id="id18">TensorFlow-Specific Parameters</a></p></li>
<li><p><a class="reference internal" href="#pytorch-specific-parameters" id="id19">PyTorch-Specific Parameters</a></p></li>
<li><p><a class="reference internal" href="#common-parameters" id="id20">Common Parameters</a></p></li>
</ul>
</li>
</ul>
</nav>
<section id="library-attribution">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">Library Attribution</a><a class="headerlink" href="#library-attribution" title="Link to this heading"></a></h2>
<p>SignXAI builds upon two powerful explainability libraries, each providing the backend implementation for various explanation methods:</p>
<ul class="simple">
<li><p><strong>iNNvestigate</strong>: Powers the TensorFlow implementation of Layer-wise Relevance Propagation (LRP) and other methods</p>
<ul>
<li><p>Developed at TU Berlin by M. Alber et al.</p></li>
<li><p>Original paper: <a class="reference external" href="https://doi.org/10.1007/s00521-019-04041-y">iNNvestigate neural networks!</a></p></li>
<li><p>Repository: <a class="reference external" href="https://github.com/albermax/innvestigate">github.com/albermax/innvestigate</a></p></li>
</ul>
</li>
<li><p><strong>Zennit</strong>: Powers the PyTorch implementation of Layer-wise Relevance Propagation (LRP) variants</p>
<ul>
<li><p>Developed at TU Berlin by C. Anders et al.</p></li>
<li><p>Original paper: <a class="reference external" href="https://arxiv.org/abs/2106.13200">Software for Dataset-wide XAI</a></p></li>
<li><p>Repository: <a class="reference external" href="https://github.com/chr5tphr/zennit">github.com/chr5tphr/zennit</a></p></li>
</ul>
</li>
</ul>
<p>The SIGN method, which is SignXAI’s novel contribution, builds upon these libraries to provide improved explanations by reducing bias.</p>
</section>
<section id="method-overview">
<h2><a class="toc-backref" href="#id3" role="doc-backlink">Method Overview</a><a class="headerlink" href="#method-overview" title="Link to this heading"></a></h2>
<p>The table below shows all available explanation methods in SignXAI. Methods are implemented as follows:</p>
<ul class="simple">
<li><p><strong>Gradient-based methods</strong>: Direct implementation in both TensorFlow and PyTorch</p></li>
<li><p><strong>Guided Backpropagation</strong>: Direct implementation in both TensorFlow and PyTorch</p></li>
<li><p><strong>Grad-CAM</strong>: Direct implementation in both TensorFlow and PyTorch</p></li>
<li><p><strong>LRP methods (TensorFlow)</strong>: Implemented using iNNvestigate</p></li>
<li><p><strong>LRP methods (PyTorch)</strong>: Implemented using Zennit</p></li>
<li><p><strong>SIGN method</strong>: Original SignXAI contribution, extending both iNNvestigate and Zennit</p></li>
</ul>
<table class="docutils align-default" id="id1">
<caption><span class="caption-text">Available Explanation Methods</span><a class="headerlink" href="#id1" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 22.2%" />
<col style="width: 55.6%" />
<col style="width: 11.1%" />
<col style="width: 11.1%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Method Name</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>TensorFlow</p></th>
<th class="head"><p>PyTorch</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">gradient</span></code></p></td>
<td><p>Vanilla gradient</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">input_t_gradient</span></code> or <code class="docutils literal notranslate"><span class="pre">gradient_x_input</span></code></p></td>
<td><p>Gradient multiplied by input</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">gradient_x_sign</span></code></p></td>
<td><p>Gradient multiplied by sign of input</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">gradient_x_sign_mu</span></code></p></td>
<td><p>Gradient multiplied by sign with threshold mu</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">guided_backprop</span></code></p></td>
<td><p>Guided backpropagation</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">guided_backprop_x_sign</span></code></p></td>
<td><p>Guided backpropagation multiplied by sign</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">guided_backprop_x_sign_mu</span></code></p></td>
<td><p>Guided backpropagation multiplied by sign with threshold mu</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">integrated_gradients</span></code></p></td>
<td><p>Integrated gradients</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">smoothgrad</span></code></p></td>
<td><p>SmoothGrad</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">smoothgrad_x_sign</span></code></p></td>
<td><p>SmoothGrad multiplied by sign</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">vargrad</span></code></p></td>
<td><p>VarGrad</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">deconvnet</span></code></p></td>
<td><p>DeconvNet</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">grad_cam</span></code></p></td>
<td><p>Grad-CAM</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">grad_cam_timeseries</span></code></p></td>
<td><p>Grad-CAM for time series data</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">lrp_z</span></code></p></td>
<td><p>LRP-Z rule</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">lrpsign_z</span></code></p></td>
<td><p>LRP-Z with SIGN input layer rule</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">lrp_epsilon_{value}</span></code></p></td>
<td><p>LRP-epsilon with specified epsilon value</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">lrpsign_epsilon_{value}</span></code></p></td>
<td><p>LRP-epsilon with SIGN input layer rule</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">lrp_epsilon_{value}_std_x</span></code></p></td>
<td><p>LRP-epsilon with epsilon proportional to input std</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">lrp_alpha_1_beta_0</span></code></p></td>
<td><p>LRP-AlphaBeta with alpha=1, beta=0</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">lrpsign_alpha_1_beta_0</span></code></p></td>
<td><p>LRP-AlphaBeta with SIGN input layer rule</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">lrp_sequential_composite_a</span></code></p></td>
<td><p>LRP composite with layer-specific rules (variant A)</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">lrp_sequential_composite_b</span></code></p></td>
<td><p>LRP composite with layer-specific rules (variant B)</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
</tbody>
</table>
</section>
<section id="gradient-based-methods">
<h2><a class="toc-backref" href="#id4" role="doc-backlink">Gradient-Based Methods</a><a class="headerlink" href="#gradient-based-methods" title="Link to this heading"></a></h2>
<p><em>Implemented directly in SignXAI with framework-specific optimizations</em></p>
<section id="vanilla-gradient">
<h3><a class="toc-backref" href="#id5" role="doc-backlink">Vanilla Gradient</a><a class="headerlink" href="#vanilla-gradient" title="Link to this heading"></a></h3>
<p>Method name: <code class="docutils literal notranslate"><span class="pre">gradient</span></code></p>
<p>Computes the gradient of the target output with respect to the input, highlighting features that have the greatest effect on the output.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) for which to compute the gradient (default: argmax)</p></li>
</ul>
</section>
<section id="gradient-x-input">
<h3><a class="toc-backref" href="#id6" role="doc-backlink">Gradient x Input</a><a class="headerlink" href="#gradient-x-input" title="Link to this heading"></a></h3>
<p>Method name: <code class="docutils literal notranslate"><span class="pre">input_t_gradient</span></code> or <code class="docutils literal notranslate"><span class="pre">gradient_x_input</span></code></p>
<p>Element-wise multiplication of the gradient with the input to reduce noise and improve visualization.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) for which to compute the gradient (default: argmax)</p></li>
</ul>
</section>
<section id="gradient-x-sign">
<h3><a class="toc-backref" href="#id7" role="doc-backlink">Gradient x SIGN</a><a class="headerlink" href="#gradient-x-sign" title="Link to this heading"></a></h3>
<p>Method name: <code class="docutils literal notranslate"><span class="pre">gradient_x_sign</span></code></p>
<p>Multiplies the gradient with the sign of the input, focusing on the input’s direction rather than magnitude.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) for which to compute the gradient (default: argmax)</p></li>
</ul>
<p>Method name: <code class="docutils literal notranslate"><span class="pre">gradient_x_sign_mu</span></code></p>
<p>Includes a threshold parameter mu for more flexible sign thresholding.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mu</span></code>: Threshold parameter (default: 0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) for which to compute the gradient (default: argmax)</p></li>
</ul>
</section>
<section id="integrated-gradients">
<h3><a class="toc-backref" href="#id8" role="doc-backlink">Integrated Gradients</a><a class="headerlink" href="#integrated-gradients" title="Link to this heading"></a></h3>
<p>Method name: <code class="docutils literal notranslate"><span class="pre">integrated_gradients</span></code></p>
<p>Computes gradients along a straight-line path from a baseline to the input to better attribute feature importance.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">steps</span></code>: Number of steps for integration (default: 50)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">reference_inputs</span></code>: Baseline input (default: zeros)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) for which to compute the gradient (default: argmax)</p></li>
</ul>
</section>
<section id="smoothgrad">
<h3><a class="toc-backref" href="#id9" role="doc-backlink">SmoothGrad</a><a class="headerlink" href="#smoothgrad" title="Link to this heading"></a></h3>
<p>Method name: <code class="docutils literal notranslate"><span class="pre">smoothgrad</span></code></p>
<p>Computes average gradients from multiple input samples with added noise to produce smoother, more visually interpretable heatmaps.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">augment_by_n</span></code>: Number of noisy samples (default: 50)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">noise_scale</span></code>: Scale of Gaussian noise (default: 0.2)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) for which to compute the gradient (default: argmax)</p></li>
</ul>
</section>
</section>
<section id="guided-backpropagation">
<h2><a class="toc-backref" href="#id10" role="doc-backlink">Guided Backpropagation</a><a class="headerlink" href="#guided-backpropagation" title="Link to this heading"></a></h2>
<p><em>Implemented directly in SignXAI with framework-specific optimizations</em></p>
<p>Method name: <code class="docutils literal notranslate"><span class="pre">guided_backprop</span></code></p>
<p>Modifies the ReLU gradient to only pass positive gradients, producing sharper visualization.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) for which to compute the gradient (default: argmax)</p></li>
</ul>
<p>Method name: <code class="docutils literal notranslate"><span class="pre">guided_backprop_x_sign</span></code></p>
<p>Multiplies guided backpropagation with the sign of the input for enhanced visualization.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) for which to compute the gradient (default: argmax)</p></li>
</ul>
<p>Method name: <code class="docutils literal notranslate"><span class="pre">guided_backprop_x_sign_mu</span></code></p>
<p>Includes a threshold parameter mu for more flexible sign thresholding.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mu</span></code>: Threshold parameter</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) for which to compute the gradient (default: argmax)</p></li>
</ul>
</section>
<section id="grad-cam">
<h2><a class="toc-backref" href="#id11" role="doc-backlink">Grad-CAM</a><a class="headerlink" href="#grad-cam" title="Link to this heading"></a></h2>
<p><em>Implemented directly in SignXAI with framework-specific optimizations</em></p>
<p>Method name: <code class="docutils literal notranslate"><span class="pre">grad_cam</span></code></p>
<p>Generates a localization map highlighting important regions by using the gradients flowing into the final convolutional layer.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">last_conv_layer_name</span></code>: Name of the last convolutional layer (auto-detected if None)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) (default: argmax)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">resize</span></code>: Whether to resize the output to match input dimensions (default: True)</p></li>
</ul>
<p>Method name: <code class="docutils literal notranslate"><span class="pre">grad_cam_timeseries</span></code></p>
<p>Specialized version of Grad-CAM for time series data.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">last_conv_layer_name</span></code>: Name of the last convolutional layer (auto-detected if None)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) (default: argmax)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">resize</span></code>: Whether to resize the output to match input dimensions (default: True)</p></li>
</ul>
</section>
<section id="layer-wise-relevance-propagation-lrp">
<h2><a class="toc-backref" href="#id12" role="doc-backlink">Layer-wise Relevance Propagation (LRP)</a><a class="headerlink" href="#layer-wise-relevance-propagation-lrp" title="Link to this heading"></a></h2>
<p><em>TensorFlow implementation provided by iNNvestigate; PyTorch implementation provided by Zennit</em></p>
<section id="lrp-base-methods">
<h3><a class="toc-backref" href="#id13" role="doc-backlink">LRP Base Methods</a><a class="headerlink" href="#lrp-base-methods" title="Link to this heading"></a></h3>
<p>Method name: <code class="docutils literal notranslate"><span class="pre">lrp_z</span></code></p>
<p>Basic LRP implementation following the z-rule.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) (default: argmax)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_layer_rule</span></code>: Rule for the input layer (default: None)</p></li>
</ul>
<p>Method name: <code class="docutils literal notranslate"><span class="pre">lrpsign_z</span></code></p>
<p>LRP-Z with SIGN input layer rule.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) (default: argmax)</p></li>
</ul>
</section>
<section id="lrp-with-epsilon">
<h3><a class="toc-backref" href="#id14" role="doc-backlink">LRP with Epsilon</a><a class="headerlink" href="#lrp-with-epsilon" title="Link to this heading"></a></h3>
<p>Methods: <code class="docutils literal notranslate"><span class="pre">lrp_epsilon_{value}</span></code> (e.g., <code class="docutils literal notranslate"><span class="pre">lrp_epsilon_0_1</span></code>, <code class="docutils literal notranslate"><span class="pre">lrp_epsilon_1</span></code>, etc.)</p>
<p>LRP with epsilon stabilization factor.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) (default: argmax)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_layer_rule</span></code>: Rule for the input layer (default: None)</p></li>
</ul>
<p>Methods: <code class="docutils literal notranslate"><span class="pre">lrpsign_epsilon_{value}</span></code> (e.g., <code class="docutils literal notranslate"><span class="pre">lrpsign_epsilon_0_1</span></code>)</p>
<p>LRP-epsilon with SIGN input layer rule.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) (default: argmax)</p></li>
</ul>
<p>Methods: <code class="docutils literal notranslate"><span class="pre">lrp_epsilon_{value}_std_x</span></code> (e.g., <code class="docutils literal notranslate"><span class="pre">lrp_epsilon_0_1_std_x</span></code>)</p>
<p>LRP with epsilon proportional to the standard deviation of the input.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) (default: argmax)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_layer_rule</span></code>: Rule for the input layer (default: None)</p></li>
</ul>
</section>
<section id="lrp-with-alpha-beta">
<h3><a class="toc-backref" href="#id15" role="doc-backlink">LRP with Alpha-Beta</a><a class="headerlink" href="#lrp-with-alpha-beta" title="Link to this heading"></a></h3>
<p>Method name: <code class="docutils literal notranslate"><span class="pre">lrp_alpha_1_beta_0</span></code></p>
<p>LRP with separate treatment of positive and negative contributions.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) (default: argmax)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_layer_rule</span></code>: Rule for the input layer (default: None)</p></li>
</ul>
<p>Method name: <code class="docutils literal notranslate"><span class="pre">lrpsign_alpha_1_beta_0</span></code></p>
<p>LRP Alpha-Beta with SIGN input layer rule.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) (default: argmax)</p></li>
</ul>
</section>
<section id="lrp-composite-rules">
<h3><a class="toc-backref" href="#id16" role="doc-backlink">LRP Composite Rules</a><a class="headerlink" href="#lrp-composite-rules" title="Link to this heading"></a></h3>
<p>Method name: <code class="docutils literal notranslate"><span class="pre">lrp_sequential_composite_a</span></code></p>
<p>LRP with layer-specific rules (variant A).</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) (default: argmax)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_layer_rule</span></code>: Rule for the input layer (default: None)</p></li>
</ul>
<p>Method name: <code class="docutils literal notranslate"><span class="pre">lrp_sequential_composite_b</span></code></p>
<p>LRP with layer-specific rules (variant B).</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target output neuron (class) (default: argmax)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_layer_rule</span></code>: Rule for the input layer (default: None)</p></li>
</ul>
</section>
</section>
<section id="framework-specific-parameters">
<h2><a class="toc-backref" href="#id17" role="doc-backlink">Framework-Specific Parameters</a><a class="headerlink" href="#framework-specific-parameters" title="Link to this heading"></a></h2>
<p>Some parameters have different meanings or implementations between TensorFlow and PyTorch.</p>
<section id="tensorflow-specific-parameters">
<h3><a class="toc-backref" href="#id18" role="doc-backlink">TensorFlow-Specific Parameters</a><a class="headerlink" href="#tensorflow-specific-parameters" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">model_no_softmax</span></code>: Model with softmax removed (done automatically)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_layer_rule</span></code>: Input layer rule for LRP methods (‘Z’, ‘SIGN’, ‘Bounded’, ‘WSquare’, ‘Flat’)</p></li>
</ul>
</section>
<section id="pytorch-specific-parameters">
<h3><a class="toc-backref" href="#id19" role="doc-backlink">PyTorch-Specific Parameters</a><a class="headerlink" href="#pytorch-specific-parameters" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">target_layer</span></code>: Target layer for Grad-CAM (auto-detected if None)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rule</span></code>: LRP rule in Zennit implementation (‘epsilon’, ‘zplus’, ‘alphabeta’)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rule_type</span></code>: Advanced LRP rule type (‘alpha1beta0’, ‘epsilon’, ‘gamma’, etc.)</p></li>
</ul>
</section>
<section id="common-parameters">
<h3><a class="toc-backref" href="#id20" role="doc-backlink">Common Parameters</a><a class="headerlink" href="#common-parameters" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">target_class</span></code>: Target class index (used in PyTorch implementation)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">neuron_selection</span></code>: Target neuron/class (used in TensorFlow implementation)</p></li>
</ul>
<p>Both have the same meaning and can be used interchangeably depending on the framework.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="utils.html" class="btn btn-neutral float-left" title="Utilities" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, SignXAI Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>