{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow ECG Model Tutorial - SignXAI2 Time Series Explainability\n",
    "\n",
    "This tutorial demonstrates how to use SignXAI2 to explain TensorFlow ECG classification models, following the structure from the official documentation.\n",
    "\n",
    "## ‚ö†Ô∏è Data Requirements\n",
    "\n",
    "**This tutorial requires ECG data from the repository:**\n",
    "\n",
    "```bash\n",
    "# Clone the repository to get the complete dataset\n",
    "git clone https://github.com/your-repo/signxai2.git\n",
    "```\n",
    "\n",
    "**Required data files:**\n",
    "- ECG records in `examples/data/timeseries/`\n",
    "- Pre-trained models in `examples/data/models/tensorflow/ECG/`\n",
    "- Utility functions for ECG processing\n",
    "\n",
    "The PyPI package alone doesn't include ECG data to keep the package size manageable.\n",
    "\n",
    "## What you'll learn:\n",
    "\n",
    "1. **TensorFlow ECG Models**: Building CNN models for time series classification\n",
    "2. **ECG Data Processing**: Loading and preprocessing 12-lead ECG data\n",
    "3. **Time Series XAI**: Applying various explainability methods to sequential data\n",
    "4. **12-Lead Visualization**: Creating professional medical visualizations\n",
    "5. **Multiple Methods**: Comparing different XAI approaches\n",
    "6. **Dynamic Method Parsing**: Using the new unified API with embedded parameters\n",
    "\n",
    "## ECG Signal Components:\n",
    "Understanding what the model should focus on:\n",
    "- **P-wave**: Atrial depolarization (0.08-0.12 sec)\n",
    "- **QRS complex**: Ventricular depolarization (0.06-0.10 sec)  \n",
    "- **T-wave**: Ventricular repolarization (0.16 sec)\n",
    "- **PR interval**: AV conduction time (0.12-0.20 sec)\n",
    "- **QT interval**: Total ventricular activity (0.35-0.44 sec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# SignXAI imports\n",
    "from signxai import explain, list_methods\n",
    "\n",
    "# Add project root to path for utility imports\n",
    "current_dir = os.getcwd()\n",
    "project_root = os.path.dirname(os.path.dirname(os.path.dirname(current_dir)))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Import ECG utilities (from quickstart files)\n",
    "try:\n",
    "    from utils.ecg_data import load_and_preprocess_ecg\n",
    "    from utils.ecg_visualization import plot_ecg\n",
    "    from utils.ecg_explainability import normalize_ecg_relevancemap\n",
    "    print(\"‚úÖ ECG utilities loaded successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è ECG utilities not available: {e}\")\n",
    "    print(\"Please ensure you have the complete repository with utils/ directory\")\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "\n",
    "# ECG lead names for reference\n",
    "LEAD_NAMES = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "print(f\"\\n12-Lead ECG configuration: {', '.join(LEAD_NAMES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic ECG Data\n",
    "\n",
    "Following the documentation approach (lines 75-92), we'll generate synthetic ECG data with characteristic patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data (in practice, you would use real ECG datasets)\n",
    "def generate_synthetic_ecg_data(n_samples=1000, seq_length=1000, n_classes=2):\n",
    "    X = np.random.randn(n_samples, seq_length, 1) * 0.1\n",
    "    # Add synthetic patterns for different classes\n",
    "    for i in range(n_samples):\n",
    "        if i % n_classes == 0:  # Class 0: Normal\n",
    "            # Add normal QRS complex\n",
    "            X[i, 400:420, 0] += np.sin(np.linspace(0, np.pi, 20)) * 1.0\n",
    "            X[i, 350:370, 0] += np.sin(np.linspace(0, np.pi, 20)) * 0.2  # P wave\n",
    "            X[i, 450:480, 0] += np.sin(np.linspace(0, np.pi, 30)) * 0.3  # T wave\n",
    "        else:  # Class 1: Abnormal\n",
    "            # Add abnormal QRS complex\n",
    "            X[i, 380:410, 0] += np.sin(np.linspace(0, np.pi, 30)) * 0.8\n",
    "            X[i, 420:460, 0] -= np.sin(np.linspace(0, np.pi, 40)) * 0.4\n",
    "            \n",
    "    # Create labels\n",
    "    y = np.array([i % n_classes for i in range(n_samples)])\n",
    "    return X, y\n",
    "\n",
    "# Generate data\n",
    "X_train, y_train = generate_synthetic_ecg_data(800, 1000, 2)\n",
    "X_test, y_test = generate_synthetic_ecg_data(200, 1000, 2)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "\n",
    "# Visualize some samples\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sample_idx = i * 50\n",
    "    plt.plot(X_test[sample_idx, :, 0])\n",
    "    plt.title(f'Sample {sample_idx}, Class: {y_test[sample_idx]}')\n",
    "    plt.xlabel('Time (samples)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create TensorFlow CNN Model for ECG Classification\n",
    "\n",
    "Following the documentation structure (lines 98-113), we'll create a CNN model for ECG classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CNN model for ECG classification\n",
    "def create_ecg_model(seq_length=1000):\n",
    "    model = Sequential([\n",
    "        Conv1D(16, kernel_size=5, activation='relu', input_shape=(seq_length, 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(32, kernel_size=5, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(64, kernel_size=5, activation='relu', name='conv1d_2'),  # Named for Grad-CAM\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(2)  # No activation (logits)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "model = create_ecg_model()\n",
    "print(\"Model created successfully!\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Model\n",
    "\n",
    "Following the documentation training procedure (lines 115-127)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'\\n‚úÖ Training completed!')\n",
    "print(f'Test accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Sample for XAI Analysis\n",
    "\n",
    "Following the documentation approach (lines 129-149), we'll prepare a sample for explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and sample\n",
    "ecg_sample = X_test[0, :, 0]  # First test sample, remove channel dimension for visualization\n",
    "\n",
    "# Prepare input with batch dimension\n",
    "x = ecg_sample.reshape(1, 1000, 1)\n",
    "\n",
    "print(f\"Sample shape for XAI: {x.shape}\")\n",
    "print(f\"Sample shape for visualization: {ecg_sample.shape}\")\n",
    "\n",
    "# Get prediction\n",
    "preds = model.predict(x, verbose=0)\n",
    "predicted_class = np.argmax(preds[0])\n",
    "class_names = ['Normal', 'Abnormal']\n",
    "\n",
    "print(f\"Predicted class: {predicted_class} ({class_names[predicted_class]})\")\n",
    "print(f\"Confidence: {tf.nn.softmax(preds)[0, predicted_class]:.4f}\")\n",
    "\n",
    "# Visualize the sample\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(ecg_sample)\n",
    "plt.title(f'ECG Sample for XAI Analysis\\nPredicted: {class_names[predicted_class]} (confidence: {tf.nn.softmax(preds)[0, predicted_class]:.3f})')\n",
    "plt.xlabel('Time (samples)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Explanations with Multiple Methods\n",
    "\n",
    "Following the documentation structure (lines 150-179), we'll calculate explanations with different methods including Grad-CAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate explanations with different methods\n",
    "methods = [\n",
    "    'gradient',\n",
    "    'gradient_x_input',\n",
    "    'integrated_gradients',\n",
    "    'grad_cam',  # Works for time series too\n",
    "    'lrp_z',\n",
    "    'lrp_epsilon_0_1',\n",
    "    'lrpsign_z'  # The SIGN method\n",
    "]\n",
    "\n",
    "explanations = {}\n",
    "print(\"Calculating explanations...\")\n",
    "\n",
    "for method in methods:\n",
    "    try:\n",
    "        print(f\"  Computing: {method}\")\n",
    "        if method == 'grad_cam':\n",
    "            explanations[method] = explain(\n",
    "                model=model,\n",
    "                x=x,\n",
    "                method_name=method,\n",
    "                target_class=predicted_class,\n",
    "                last_conv_layer_name='conv1d_2'\n",
    "            )\n",
    "        else:\n",
    "            explanations[method] = explain(\n",
    "                model=model,\n",
    "                x=x,\n",
    "                method_name=method,\n",
    "                target_class=predicted_class\n",
    "            )\n",
    "        print(f\"    ‚úÖ Success\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ùå Failed: {e}\")\n",
    "        # Create dummy explanation for visualization\n",
    "        explanations[method] = np.zeros_like(x)\n",
    "\n",
    "print(f\"\\n‚úÖ Generated explanations for {len(explanations)} methods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Separate Explanations\n",
    "\n",
    "Following the documentation approach (lines 180-201), we'll create separate plots for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize explanations\n",
    "fig, axs = plt.subplots(len(methods) + 1, 1, figsize=(15, 3*(len(methods) + 1)))\n",
    "\n",
    "# Original signal\n",
    "axs[0].plot(ecg_sample)\n",
    "axs[0].set_title('Original ECG Signal')\n",
    "axs[0].set_ylabel('Amplitude')\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Explanations\n",
    "for i, method in enumerate(methods):\n",
    "    if method in explanations:\n",
    "        # Reshape explanation to 1D\n",
    "        if isinstance(explanations[method], tf.Tensor):\n",
    "            expl = explanations[method].numpy()[0, :, 0]\n",
    "        else:\n",
    "            expl = explanations[method][0, :, 0]\n",
    "        \n",
    "        # Plot explanation\n",
    "        axs[i+1].plot(expl)\n",
    "        axs[i+1].set_title(f'Method: {method}')\n",
    "        axs[i+1].set_ylabel('Attribution')\n",
    "        axs[i+1].grid(True)\n",
    "    else:\n",
    "        axs[i+1].text(0.5, 0.5, 'Method failed', transform=axs[i+1].transAxes, ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Overlay Visualizations\n",
    "\n",
    "Following the documentation approach (lines 202-222), we'll create overlay visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative visualization: Overlay explanation on signal\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    if method not in explanations:\n",
    "        continue\n",
    "        \n",
    "    plt.subplot(len(methods), 1, i+1)\n",
    "    \n",
    "    # Original signal\n",
    "    plt.plot(ecg_sample, 'gray', alpha=0.5, label='ECG Signal')\n",
    "    \n",
    "    # Explanation\n",
    "    if isinstance(explanations[method], tf.Tensor):\n",
    "        expl = explanations[method].numpy()[0, :, 0]\n",
    "    else:\n",
    "        expl = explanations[method][0, :, 0]\n",
    "        \n",
    "    expl_norm = (expl - expl.min()) / (expl.max() - expl.min()) if expl.max() > expl.min() else expl\n",
    "    plt.plot(expl_norm, 'r', label='Attribution')\n",
    "    \n",
    "    plt.title(f'Method: {method}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced ECG Component Analysis\n",
    "\n",
    "Following the documentation approach for advanced analysis, we'll analyze specific ECG components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define characteristic ECG components (these would be expert-identified in real applications)\n",
    "p_wave_region = slice(350, 370)\n",
    "qrs_complex_region = slice(400, 420)\n",
    "t_wave_region = slice(450, 480)\n",
    "\n",
    "# Calculate the mean attribution for each region using LRP-SIGN method\n",
    "if 'lrpsign_z' in explanations:\n",
    "    if isinstance(explanations['lrpsign_z'], tf.Tensor):\n",
    "        lrpsign_expl = explanations['lrpsign_z'].numpy()[0, :, 0]\n",
    "    else:\n",
    "        lrpsign_expl = explanations['lrpsign_z'][0, :, 0]\n",
    "    \n",
    "    p_wave_attr = np.mean(np.abs(lrpsign_expl[p_wave_region]))\n",
    "    qrs_complex_attr = np.mean(np.abs(lrpsign_expl[qrs_complex_region]))\n",
    "    t_wave_attr = np.mean(np.abs(lrpsign_expl[t_wave_region]))\n",
    "    \n",
    "    # Visualize with region highlighting\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Plot original ECG\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(ecg_sample)\n",
    "    \n",
    "    # Highlight ECG components\n",
    "    plt.axvspan(350, 370, color='blue', alpha=0.2, label='P-wave')\n",
    "    plt.axvspan(400, 420, color='red', alpha=0.2, label='QRS Complex')\n",
    "    plt.axvspan(450, 480, color='green', alpha=0.2, label='T-wave')\n",
    "    \n",
    "    plt.title('ECG Signal with Components')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot explanation with component attribution\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(lrpsign_expl)\n",
    "    \n",
    "    # Highlight attribution in ECG components\n",
    "    plt.axvspan(350, 370, color='blue', alpha=0.2)\n",
    "    plt.axvspan(400, 420, color='red', alpha=0.2)\n",
    "    plt.axvspan(450, 480, color='green', alpha=0.2)\n",
    "    \n",
    "    # Add component attribution values\n",
    "    plt.text(360, max(lrpsign_expl), f'P-wave: {p_wave_attr:.4f}', \n",
    "             horizontalalignment='center', backgroundcolor='white')\n",
    "    plt.text(410, max(lrpsign_expl), f'QRS: {qrs_complex_attr:.4f}', \n",
    "             horizontalalignment='center', backgroundcolor='white')\n",
    "    plt.text(465, max(lrpsign_expl), f'T-wave: {t_wave_attr:.4f}', \n",
    "             horizontalalignment='center', backgroundcolor='white')\n",
    "    \n",
    "    plt.title('LRP-SIGN Attribution')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüîç ECG Component Analysis:\")\n",
    "    print(f\"  P-wave attribution: {p_wave_attr:.4f}\")\n",
    "    print(f\"  QRS complex attribution: {qrs_complex_attr:.4f}\")\n",
    "    print(f\"  T-wave attribution: {t_wave_attr:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è LRP-SIGN method not available for component analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 12-Lead ECG Visualization (if ECG utilities available)\n",
    "\n",
    "Using the utilities from the quickstart files to create professional ECG visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load real ECG data and create 12-lead visualization\n",
    "try:\n",
    "    # Load real ECG data from repository\n",
    "    record_id = '03509_hr'\n",
    "    ecg_src_dir = os.path.join(project_root, 'examples', 'data', 'timeseries', '')\n",
    "    \n",
    "    print(f\"Loading ECG data for record: {record_id}...\")\n",
    "    ecg_data = load_and_preprocess_ecg(\n",
    "        record_id=record_id,\n",
    "        src_dir=ecg_src_dir,\n",
    "        ecg_filters=['BWR', 'BLA', 'AC50Hz', 'LP40Hz'],\n",
    "        subsampling_window_size=3000,\n",
    "        subsample_start=0\n",
    "    )\n",
    "    \n",
    "    if ecg_data is not None:\n",
    "        print(f\"‚úÖ ECG data loaded: {ecg_data.shape}\")\n",
    "        \n",
    "        # Use single lead for model prediction\n",
    "        ecg_single_lead = ecg_data[:, 0:1]  # Shape: (3000, 1)\n",
    "        \n",
    "        # TensorFlow expects shape: (timesteps, channels)\n",
    "        input_data = ecg_single_lead.astype(np.float32)\n",
    "        \n",
    "        # Get prediction and explanation for real ECG\n",
    "        predictions = model.predict(np.expand_dims(input_data, 0), verbose=0)\n",
    "        predicted_idx = np.argmax(predictions[0])\n",
    "        \n",
    "        # Calculate explanation with one method\n",
    "        explanation = explain(\n",
    "            model,\n",
    "            input_data,  # No batch dimension needed for SignXAI\n",
    "            method_name=\"gradient_x_input\",\n",
    "            target_class=predicted_idx\n",
    "        )\n",
    "        \n",
    "        # Process for visualization\n",
    "        if isinstance(explanation, tf.Tensor):\n",
    "            explanation_np = explanation.numpy()\n",
    "        else:\n",
    "            explanation_np = explanation\n",
    "        \n",
    "        # Handle shape processing for relevance map\n",
    "        if explanation_np.ndim == 1:\n",
    "            relevance_map = explanation_np.reshape(-1, 1)\n",
    "        elif explanation_np.ndim == 2:\n",
    "            if explanation_np.shape[0] == 1:\n",
    "                relevance_map = explanation_np.transpose()\n",
    "            else:\n",
    "                relevance_map = explanation_np\n",
    "        else:\n",
    "            relevance_map = explanation_np.reshape(-1, 1)\n",
    "        \n",
    "        # Expand to 12 leads for visualization\n",
    "        if relevance_map.shape[1] == 1 and ecg_data.shape[1] == 12:\n",
    "            relevance_map = np.tile(relevance_map, (1, 12))\n",
    "        \n",
    "        # Normalize\n",
    "        normalized_relevance = normalize_ecg_relevancemap(relevance_map)\n",
    "        \n",
    "        # Format for visualization\n",
    "        ecg_for_visual = ecg_data.transpose()\n",
    "        expl_for_visual = normalized_relevance.transpose()\n",
    "        \n",
    "        # Create 12-lead visualization\n",
    "        plot_ecg(\n",
    "            ecg=ecg_for_visual,\n",
    "            explanation=expl_for_visual,\n",
    "            sampling_rate=500,\n",
    "            title=f\"TensorFlow XAI: gradient_x_input on {record_id}\",\n",
    "            show_colorbar=True,\n",
    "            cmap='seismic',\n",
    "            bubble_size=30,\n",
    "            line_width=1.0,\n",
    "            style='fancy',\n",
    "            save_to=None,\n",
    "            clim_min=-1,\n",
    "            clim_max=1,\n",
    "            colorbar_label='Relevance',\n",
    "            shape_switch=False\n",
    "        )\n",
    "        \n",
    "        print(\"\\n‚úÖ 12-lead ECG visualization created!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not create 12-lead visualization: {e}\")\n",
    "    print(\"This requires the complete repository with ECG data and utilities.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Method Comparison Analysis\n",
    "\n",
    "Let's compare attribution across different methods for ECG components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare attribution across methods\n",
    "methods_to_compare = ['gradient', 'gradient_x_input', 'lrp_z', 'lrpsign_z']\n",
    "components = ['P-wave', 'QRS Complex', 'T-wave']\n",
    "regions = [p_wave_region, qrs_complex_region, t_wave_region]\n",
    "\n",
    "# Calculate attribution for each method and component\n",
    "component_attribution = {}\n",
    "for method in methods_to_compare:\n",
    "    if method in explanations:\n",
    "        if isinstance(explanations[method], tf.Tensor):\n",
    "            expl = explanations[method].numpy()[0, :, 0]\n",
    "        else:\n",
    "            expl = explanations[method][0, :, 0]\n",
    "        component_attribution[method] = [np.mean(np.abs(expl[region])) for region in regions]\n",
    "    else:\n",
    "        component_attribution[method] = [0, 0, 0]\n",
    "\n",
    "# Visualize component attribution comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(components))\n",
    "width = 0.2\n",
    "offsets = np.linspace(-0.3, 0.3, len(methods_to_compare))\n",
    "\n",
    "for i, method in enumerate(methods_to_compare):\n",
    "    plt.bar(x + offsets[i], component_attribution[method], width, label=method)\n",
    "\n",
    "plt.xlabel('ECG Component')\n",
    "plt.ylabel('Mean Absolute Attribution')\n",
    "plt.title('Attribution Comparison Across Methods')\n",
    "plt.xticks(x, components)\n",
    "plt.legend()\n",
    "plt.grid(True, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Method Comparison Summary:\")\n",
    "for method in methods_to_compare:\n",
    "    if method in component_attribution:\n",
    "        attrs = component_attribution[method]\n",
    "        print(f\"  {method:20} - P: {attrs[0]:.3f}, QRS: {attrs[1]:.3f}, T: {attrs[2]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary and Key Insights\n",
    "\n",
    "### What we've learned:\n",
    "\n",
    "1. **TensorFlow Time Series Models**: How to build and train CNN models for ECG classification\n",
    "2. **Multiple XAI Methods**: Different approaches provide different insights:\n",
    "   - **Gradient**: Shows instantaneous importance\n",
    "   - **Gradient √ó Input**: Emphasizes strong signal regions  \n",
    "   - **Integrated Gradients**: Provides theoretically grounded attributions\n",
    "   - **Grad-CAM**: Adapts convolutional attention for time series\n",
    "   - **LRP methods**: Show layer-wise relevance propagation\n",
    "   - **LRP-SIGN**: The SIGN method for enhanced attribution\n",
    "\n",
    "3. **Visualization Techniques**: \n",
    "   - Separate plots for clear comparison\n",
    "   - Overlay visualizations for intuitive understanding\n",
    "   - Component-specific analysis for medical insights\n",
    "   - 12-lead medical visualizations for clinical applications\n",
    "\n",
    "4. **Time Series XAI**: Understanding temporal dependencies and pattern recognition in sequential data\n",
    "\n",
    "### Clinical Insights:\n",
    "- Most methods correctly highlight QRS complexes, which is clinically appropriate\n",
    "- Different methods show varying sensitivity to P-waves and T-waves\n",
    "- Component-specific analysis helps validate model focus against medical knowledge\n",
    "\n",
    "### Next Steps:\n",
    "- Try different ECG records to see consistency across samples\n",
    "- Experiment with different model architectures\n",
    "- Compare with PyTorch implementation\n",
    "- Apply to your own time series classification problems\n",
    "\n",
    "### Method Selection Guide:\n",
    "- **`gradient`**: Fast, good for real-time analysis\n",
    "- **`gradient_x_input`**: Better for highlighting strong features\n",
    "- **`integrated_gradients`**: Most theoretically sound, but slower\n",
    "- **`grad_cam`**: Good for understanding convolutional focus\n",
    "- **`lrp_*`**: Good for layer-wise understanding\n",
    "- **`lrpsign_z`**: Enhanced attribution with sign information\n",
    "\n",
    "This tutorial demonstrates how SignXAI2 can provide valuable insights into time series model decisions, particularly important in medical applications where understanding AI reasoning is critical for clinical adoption."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}