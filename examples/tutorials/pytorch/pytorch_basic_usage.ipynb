{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SignXAI2 with PyTorch - Basic Usage\n",
    "\n",
    "This tutorial demonstrates how to use SignXAI2 with PyTorch models using the new dynamic method parsing approach.\n",
    "\n",
    "## Key Features:\n",
    "- **Dynamic Method Parsing**: Parameters are embedded directly in method names\n",
    "- **Unified API**: Same interface for both TensorFlow and PyTorch\n",
    "- **No Wrappers**: Direct method calls without wrapper functions\n",
    "\n",
    "## Setup Requirements\n",
    "\n",
    "```bash\n",
    "# Install SignXAI2 with PyTorch support\n",
    "pip install signxai2[pytorch]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Suppress deprecation warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Import the unified SignXAI API\n",
    "from signxai.api import explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained VGG16 model\n",
    "print(\"Loading VGG16 model...\")\n",
    "model = models.vgg16(pretrained=True)\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image\n",
    "img_path = 'examples/data/images/example.jpg'  # Update with your image path\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "# Display the original image\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Preprocess for VGG16\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "input_tensor = preprocess(img).unsqueeze(0)  # Add batch dimension\n",
    "print(f\"Input tensor shape: {input_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model prediction\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_idx = torch.argmax(output, dim=1)\n",
    "top_probs, top_idxs = torch.topk(probabilities, 5)\n",
    "\n",
    "print(\"Top 5 predictions:\")\n",
    "for i, (prob, idx) in enumerate(zip(top_probs, top_idxs)):\n",
    "    print(f\"  {i+1}. Class {idx.item()}: {prob.item()*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nUsing class {predicted_idx.item()} for explanation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Explanations with Dynamic Method Parsing\n",
    "\n",
    "### New Feature: Dynamic Method Parsing\n",
    "Parameters are now embedded directly in the method name. For example:\n",
    "- `gradient` - Basic gradient\n",
    "- `gradient_x_input` - Gradient Ã— Input\n",
    "- `gradient_x_input_x_sign_mu_neg_0_5` - Complex combination with parameter\n",
    "- `smoothgrad_noise_0_3_samples_50` - SmoothGrad with custom parameters\n",
    "- `lrp_epsilon_0_25` - LRP with epsilon=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Basic gradient\n",
    "method = \"gradient\"\n",
    "print(f\"Calculating explanation using: {method}\")\n",
    "\n",
    "explanation_gradient = explain(\n",
    "    model,\n",
    "    input_tensor,\n",
    "    method_name=method,\n",
    "    target_class=predicted_idx.item()\n",
    ")\n",
    "\n",
    "print(f\"Explanation shape: {explanation_gradient.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Gradient with transformations and parameters\n",
    "method = \"gradient_x_input_x_sign_mu_neg_0_5\"\n",
    "print(f\"Calculating explanation using: {method}\")\n",
    "\n",
    "explanation_complex = explain(\n",
    "    model,\n",
    "    input_tensor,\n",
    "    method_name=method,\n",
    "    target_class=predicted_idx.item()\n",
    ")\n",
    "\n",
    "print(f\"Explanation shape: {explanation_complex.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: SmoothGrad with custom parameters\n",
    "method = \"smoothgrad_noise_0_3_samples_50\"\n",
    "print(f\"Calculating explanation using: {method}\")\n",
    "\n",
    "explanation_smoothgrad = explain(\n",
    "    model,\n",
    "    input_tensor,\n",
    "    method_name=method,\n",
    "    target_class=predicted_idx.item()\n",
    ")\n",
    "\n",
    "print(f\"Explanation shape: {explanation_smoothgrad.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Multiple methods with dynamic parameters\n",
    "methods = [\n",
    "    \"gradient\",\n",
    "    \"gradient_x_input\",\n",
    "    \"gradient_x_sign\",\n",
    "    \"smoothgrad\",\n",
    "    \"smoothgrad_noise_0_1_samples_25\",\n",
    "    \"integrated_gradients\",\n",
    "    \"integrated_gradients_steps_100\",\n",
    "    \"guided_backprop\",\n",
    "    \"deconvnet\",\n",
    "    \"lrp_epsilon_0_25\",\n",
    "    \"lrp_epsilon_50_x_sign\",\n",
    "    \"lrp_alpha_2_beta_1\"\n",
    "]\n",
    "\n",
    "explanations = {}\n",
    "for method in methods:\n",
    "    try:\n",
    "        print(f\"Calculating: {method}\")\n",
    "        explanation = explain(\n",
    "            model,\n",
    "            input_tensor,\n",
    "            method_name=method,\n",
    "            target_class=predicted_idx.item()\n",
    "        )\n",
    "        explanations[method] = explanation\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed: {e}\")\n",
    "\n",
    "print(f\"\\nSuccessfully calculated {len(explanations)} explanations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_explanation(explanation):\n",
    "    \"\"\"Process explanation for visualization.\"\"\"\n",
    "    # Convert to numpy if needed\n",
    "    if hasattr(explanation, 'detach'):\n",
    "        explanation_np = explanation.detach().cpu().numpy()\n",
    "    else:\n",
    "        explanation_np = explanation\n",
    "    \n",
    "    # Remove batch dimension if present\n",
    "    if explanation_np.ndim == 4:\n",
    "        explanation_np = explanation_np[0]\n",
    "    \n",
    "    # Sum over channels to create 2D heatmap\n",
    "    if explanation_np.ndim == 3:\n",
    "        heatmap = explanation_np.sum(axis=0)\n",
    "    else:\n",
    "        heatmap = explanation_np\n",
    "    \n",
    "    # Normalize for visualization\n",
    "    abs_max = np.max(np.abs(heatmap))\n",
    "    if abs_max > 0:\n",
    "        normalized = heatmap / abs_max\n",
    "    else:\n",
    "        normalized = heatmap\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def visualize_explanations(explanations, original_img, cols=3):\n",
    "    \"\"\"Visualize multiple explanations in a grid.\"\"\"\n",
    "    n_methods = len(explanations)\n",
    "    rows = (n_methods + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 5*rows))\n",
    "    axes = axes.flatten() if n_methods > 1 else [axes]\n",
    "    \n",
    "    # Convert original image for display\n",
    "    img_np = np.array(original_img.resize((224, 224))) / 255.0\n",
    "    \n",
    "    for idx, (method_name, explanation) in enumerate(explanations.items()):\n",
    "        heatmap = process_explanation(explanation)\n",
    "        \n",
    "        axes[idx].imshow(img_np)\n",
    "        axes[idx].imshow(heatmap, cmap='seismic', alpha=0.5, clim=(-1, 1))\n",
    "        axes[idx].set_title(method_name.replace('_', ' ').title())\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(n_methods, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize All Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all calculated explanations\n",
    "if explanations:\n",
    "    visualize_explanations(explanations, img, cols=4)\n",
    "else:\n",
    "    print(\"No explanations to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compare Different Parameter Settings\n",
    "\n",
    "Let's compare how different parameters affect the same base method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare SmoothGrad with different noise levels and sample counts\n",
    "smoothgrad_variants = [\n",
    "    \"smoothgrad\",  # Default parameters\n",
    "    \"smoothgrad_noise_0_1_samples_25\",\n",
    "    \"smoothgrad_noise_0_3_samples_50\",\n",
    "    \"smoothgrad_noise_0_5_samples_100\"\n",
    "]\n",
    "\n",
    "smoothgrad_explanations = {}\n",
    "for method in smoothgrad_variants:\n",
    "    print(f\"Calculating: {method}\")\n",
    "    explanation = explain(\n",
    "        model,\n",
    "        input_tensor,\n",
    "        method_name=method,\n",
    "        target_class=predicted_idx.item()\n",
    "    )\n",
    "    smoothgrad_explanations[method] = explanation\n",
    "\n",
    "# Visualize SmoothGrad variants\n",
    "visualize_explanations(smoothgrad_explanations, img, cols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare LRP with different epsilon values\n",
    "lrp_variants = [\n",
    "    \"lrp_epsilon_0_01\",\n",
    "    \"lrp_epsilon_0_1\",\n",
    "    \"lrp_epsilon_0_25\",\n",
    "    \"lrp_epsilon_1\",\n",
    "    \"lrp_epsilon_10\"\n",
    "]\n",
    "\n",
    "lrp_explanations = {}\n",
    "for method in lrp_variants:\n",
    "    try:\n",
    "        print(f\"Calculating: {method}\")\n",
    "        explanation = explain(\n",
    "            model,\n",
    "            input_tensor,\n",
    "            method_name=method,\n",
    "            target_class=predicted_idx.item()\n",
    "        )\n",
    "        lrp_explanations[method] = explanation\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed: {e}\")\n",
    "\n",
    "# Visualize LRP variants\n",
    "if lrp_explanations:\n",
    "    visualize_explanations(lrp_explanations, img, cols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced: Method Combinations\n",
    "\n",
    "The dynamic parsing allows complex method combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex method combinations\n",
    "complex_methods = [\n",
    "    \"gradient_x_input_x_sign_mu_neg_0_5\",\n",
    "    \"lrp_epsilon_50_x_sign\",\n",
    "    \"lrpsign_epsilon_0_25_std_x\"\n",
    "]\n",
    "\n",
    "complex_explanations = {}\n",
    "for method in complex_methods:\n",
    "    try:\n",
    "        print(f\"Calculating: {method}\")\n",
    "        explanation = explain(\n",
    "            model,\n",
    "            input_tensor,\n",
    "            method_name=method,\n",
    "            target_class=predicted_idx.item()\n",
    "        )\n",
    "        complex_explanations[method] = explanation\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed: {e}\")\n",
    "\n",
    "# Visualize complex combinations\n",
    "if complex_explanations:\n",
    "    visualize_explanations(complex_explanations, img, cols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Dynamic Method Parsing**: Parameters are embedded in method names (e.g., `smoothgrad_noise_0_3_samples_50`)\n",
    "\n",
    "2. **Unified API**: Single `explain()` function works for all methods\n",
    "\n",
    "3. **No Wrappers**: Direct method calls without intermediate wrapper functions\n",
    "\n",
    "4. **Flexible Parameters**: Easy to experiment with different parameter values\n",
    "\n",
    "### Method Name Format:\n",
    "```\n",
    "base_method[_param_value][_operation][_param_value]...\n",
    "```\n",
    "\n",
    "### Examples:\n",
    "- `gradient` - Basic gradient\n",
    "- `gradient_x_input` - Gradient multiplied by input\n",
    "- `smoothgrad_noise_0_3_samples_50` - SmoothGrad with noise=0.3, samples=50\n",
    "- `lrp_epsilon_0_25` - LRP with epsilon=0.25\n",
    "- `integrated_gradients_steps_100` - Integrated Gradients with 100 steps\n",
    "\n",
    "### Next Steps:\n",
    "- Try the advanced tutorial for more complex use cases\n",
    "- Explore time series explanations with ECG data\n",
    "- Compare TensorFlow and PyTorch implementations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}